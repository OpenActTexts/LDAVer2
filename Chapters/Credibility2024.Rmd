

# Experience Rating Using Credibility Theory {#ChapCredibility}


*Chapter Preview.*    This chapter introduces credibility theory as an important actuarial tool for estimating pure premiums, frequencies, and severities for individual risks or classes of risks.  Credibility theory provides a convenient framework for combining the experience for an individual risk or class with other data to produce more stable and accurate estimates. Several models for calculating credibility estimates will be discussed including B&uuml;hlmann, B&uuml;hlmann-Straub, limited fluctuation, and nonparametric and semiparametric credibility methods.  The chapter will also show a connection between credibility theory and Bayesian estimation which was introduced in Chapter \@ref(ChBayes), `r Gloss('Bayesian Inference and Modeling')`.

## Introduction to Applications of Credibility Theory

What premium should be charged to provide insurance?  The answer depends upon the exposure to the risk of loss.  A common method to compute an insurance premium is to rate an insured using a `r Gloss('classification rating plan')`.  A classification plan is used to select an insurance rate based on an insured's rating characteristics such as geographic territory, age, etc.  All classification rating plans use a limited set of criteria to group insureds into a "class" and there will be variation in the risk of loss among insureds within the class.

An experience rating plan attempts to capture some of the variation in the risk of loss among insureds within a rating class by using the insured's own loss experience to complement the rate from the classification rating plan.  One way to do this is to use a `r Gloss('credibility weight')` $Z$ with $0\leq Z \leq 1$ to compute
$$
\hat{R}=Z\bar{X}+(1-Z)M,
$$
\begin{eqnarray*}
\hat{R}&=&\textrm{credibility weighted rate for risk,}\\
           \bar{X}&=&\textrm{average loss for the risk over a specified time period,}\\
                  M&=&\textrm{the rate for the classification group, often called the manual rate.}\\
\end{eqnarray*}
For a risk whose loss experience is stable from year to year, $Z$ might be close to 1.  For a risk whose losses vary widely from year to year, $Z$ may be close to 0.    

Credibility theory is also used for computing rates for individual classes within a classification rating plan.  When classification plan rates are being determined, some or many of the groups may not have sufficient data to produce stable and reliable rates.  The actual loss experience for a group will be assigned a credibility weight $Z$ and the `r Gloss('complement of credibility')` $1-Z$ may be given to the average experience for risks across all classes.  Or, if a class rating plan is being updated, the complement of credibility may be assigned to the current `r Gloss('class rate')`.  Credibility theory can also be applied to the calculation of expected frequencies and severities.

Computing numeric values for $Z$ requires analysis and understanding of the data.  What are the variances in the number of losses and sizes of losses for risks?  What is the variance between expected values across risks? 


```{r child = './Quizzes/Quiz91.html', eval = QUIZ}
```


## B&uuml;hlmann Credibility {#S:Sec122}

***

In this section, you learn how to:

*  Compute a credibility-weighted estimate for the expected loss for a risk or group of risks.
*  Determine the credibility $Z$ assigned to observations.
*  Calculate the values required in B&uuml;hlmann credibility including the Expected Value of the Process Variance ($EPV$), Variance of the Hypothetical Means ($VHM$) and collective mean $\mu$.

***

A classification rating plan groups policyholders together into classes based on risk characteristics. Although policyholders within a class have similarities, they are not identical and their expected losses will not be exactly the same.  An experience rating plan can supplement a class rating plan by credibility weighting an individual policyholder's loss experience with the class rate to produce a more accurate rate for the policyholder. Chapter \@ref(ChapBonusMalus) `r Gloss('Experience Rating using Bonus-Malus')` provides examples of rating plans that adjust a policyholder's rate to recognize their loss experience.

The `r Gloss('B&uuml;hlmann credibility')` model introduced in this section is often called `r Gloss('greatest accuracy credibility')`, `r Gloss('least-squares credibility')`, or `r Gloss('Bayesian credibility')`.  

In this presentation a `r Gloss('risk parameter')` $\theta$ will be assigned to each policyholder.  Losses $X$ for the policyholder with parameter $\theta$ will have a pdf $f_{X|\Theta=\theta}(x)$ and mean 
\begin{equation}
\mu(\theta)=\mathrm{E}_{X}(X|\theta)=\int xf_{x|\Theta=\theta}(x) \, dx
\end{equation}
and variance 
\begin{equation}
\sigma^2(\theta)=\mathrm{Var}_{X}(X|\theta)=\int (x-\mu(\theta))^2 f_{x|\Theta=\theta}(x) \, dx.   
\end{equation}
The integrals are over the support for the distributions. Losses $X$ can represent pure premiums, aggregate losses, number of claims, claim severities, or some other measure of loss for a period of time, often one year. Risk parameter $\theta$ may be continuous or discrete and may be multivariate depending on the model.  For a randomly selected risk the risk parameter $\theta$ is unknown but the probability density function for $\theta$ is modeled with $f_{\Theta}(\theta)$.  Averaging across the policyholders in the class the collective mean loss is
\begin{equation}
\mu=\mathrm{E_{\Theta}}[\mathrm{E_{X}}(X|\theta)]=\int f_{\Theta}(\theta)\mu(\theta)d\theta=\int f_{\Theta}(\theta) \int xf_{x|\Theta=\theta}(x) \, dx d\theta.
\end{equation}


**Example 12.2.1.** The number of claims $X$ for an insured in a class has a Poisson distribution with mean $\theta>0$.  The risk parameter $\theta$ is exponentially distributed within the class with pdf  $f(\theta)=e^{-\theta}$.  What is the expected number of claims for an insured chosen at random from the class?

`r HideExample('12.2.1','Show Example Solution')`

`r SolnBegin()` Random variable $X$ is Poisson with mean $\theta$ so $\mu(\theta)=\mathrm{E}_{X}(X|\theta)=\theta$.  The expected number of claims for a randomly chosen insured is $\mu=\mathrm{E}_{\Theta}(\mu(\theta))=\mathrm{E}_{\Theta}(\mathrm{E}_{X}(X|\theta))=\mathrm{E}_{\Theta}(\theta)=\int_{0}^{\infty}\theta e^{-\theta} d\theta=1$. 
`r SolnEnd()` 

</div>

*** 


In the prior example the risk parameter $\theta$ is a continuous random variable with an exponential distribution.  In the next example there are three types of risks and the risk parameter has a discrete distribution.  


**Example 12.2.2.**  For any risk (policyholder) in a population the number of losses $N$ in a year has a Poisson distribution with parameter $\lambda$.  Individual loss amounts $X_i$ for a risk are independent of $N$ and are iid with Type II Pareto distribution $F(x)=1-[\theta/(x+\theta)]^{\alpha}$.  There are three types of risks in the population as follows:

$$
\small{
\begin{array}{|c|c|c|c|}
\hline
\text{Risk } & \text{Percentage} & \text{Poisson} & \text{Pareto} \\
\text{Type} & \text{of Population} & \text{Parameter} & \text{Parameters} \\
\hline
A & 50\% & \lambda=0.5 & \theta=1000, \alpha=2.0 \\
B & 30\% & \lambda=1.0 & \theta=1500, \alpha=2.0 \\  
C & 20\% & \lambda=2.0 & \theta=2000, \alpha=2.0 \\              
\hline
\end{array}
}
$$

If a risk is selected at random from the population, what is the expected aggregate loss in a year?

`r HideExample('12.2.2','Show Example Solution')`

`r SolnBegin()`  The expected number of claims for a risk is $\mathrm{E}_{N}(N|\lambda$)=$\lambda$.  The expected value for a Pareto distributed random variable is $\mathrm{E}_{X}(X|\theta,\alpha$)=$\theta/(\alpha-1)$.  The expected value of the aggregate loss random variable $S=X_1+\cdots+X_N$ for a risk with parameters $\lambda$, $\alpha$, and $\theta$ assuming independence of $N$ and $X_{i}$'s is $\mathrm{E}(S|\lambda,\theta,\alpha)=\mathrm{E}_{N}(N|\lambda)\mathrm{E}_{X}(X|\theta,\alpha) = \lambda\theta/(\alpha-1)$.  The expected aggregate loss for a risk of type A is $\mathrm{E}(S_{\textrm{A}}$)=(0.5)(1000)/(2-1)=500.  The expected aggregate loss for a risk selected at random from the population is $\mathrm{E}(S)$ = 0.5[(0.5)(1000)]+0.3[(1.0)(1500)]+0.2[(2.0)(2000)]=1500.
`r SolnEnd()` 

</div>

*** 

What is the risk parameter for a risk (policyholder) in the prior example?  One could say that the risk parameter has three components $(\lambda,\theta,\alpha)$ with possible values (0.5,1000,2.0), (1.0,1500,2.0), and (2.0,2000,2.0) depending on the type of risk.

Note that in both of the examples the risk parameter is a random quantity with its own probability distribution.  We do not know the value of the risk parameter for a randomly chosen risk.   


### Credibility-Weighted Estimate for the Expected Loss {#S:Sec1221}

If a policyholder with risk parameter $\theta$ has losses $x_1, \ldots, x_n$ during $n$ time periods then the goal is to find $\mathrm{E}_{\Theta}(\mu(\theta)|x_1,\ldots, x_n)$, the conditional expectation of $\mu(\theta)$ given observations $x_1,\ldots, x_n$. Section \@ref(S:Sec123), `r Gloss('Bayesian Inference and B&uuml;hlmann Credibility')` explains how to evaluate $\mathrm{E}_{\Theta}(\mu(\theta)|x_1,\ldots, x_n)$ using Bayesian inference.  

The B&uuml;hlmann credibility model calculates a linear approximation $\hat{\mu}(\theta)=Z\bar{x}+(1-Z)\mu$ to estimate $\mathrm{E}_{\Theta}(\mu(\theta)|x_1,\ldots,x_n)$ with $\bar{x}=(x_1+\ldots+x_n)/n$.  We can rewrite this as $\hat{\mu}(\theta)=a+b\bar{x}$ which makes it obvious that the credibility estimate is a linear function of the mean.  

In the B&uuml;hlmann model, $\mathrm{E}_{\Theta}(\mu(\theta)|X_1,\ldots,X_n)$ is approximated by the linear function $a+b\bar{X}$ and 
constants $a$ and $b$ are calculated to minimize the square of the difference between these two quantities
\begin{equation}
G(a,b)=\mathrm{E}_{X}([\mathrm{E}_{\Theta}(\mu(\theta)|X_1,\ldots,X_n)-(a+b\bar{X})]^2),  
\end{equation}
hence the alternative name `r Gloss('least-squares credibility')`. Minimizing the expectation yields $b=n/(n+K)$ and $a=(1-b)\mu$. Quantity $n$ is the number of observations and $\mu=\mathrm{E}_{\Theta}(\mu(\theta))$ is the population mean.  For the moment we will assign $K$ the mysterious equation $K$ = (Expected Value of the Process Variance) / (Variance of the Hypothetical Means)=$EPV/VHM$ and will clarify the meaning at the beginning of the next section. More details about this model and calculation of $a$ and $b$ can be found in references [@Buhlmann1967], [@BuhlmannGisler2005], [@klugman2012], and [@Tse2009].


The B&uuml;hlmann credibility-weighted estimate for $\mathrm{E}_{\Theta}(\mu(\theta)|x_1,\ldots, x_n)$ for the policyholder is 
\begin{equation}
\hat{\mu}(\theta)=Z\bar{x}+(1-Z)\mu 
(\#eq:buhlcred)
\end{equation}
with
\begin{eqnarray*} 
\theta&=&\textrm{a risk parameter that identifies a policyholder's risk level}\\
\hat{\mu}(\theta)&=&\textrm{estimated expected loss for a policyholder with parameter }\theta\\
 & & \textrm{and loss experience } \bar{x}\\
\bar{x}&=&(x_1+\cdots+x_n)/n \textrm{ is the average of $n$ observations of the policyholder } \\
 Z&=&\textrm{credibility assigned to $n$ observations } = n/(n+K) \\
 K&=&EPV/VHM  \\
\mu&=&\textrm{the expected loss for a randomly chosen policyholder in the class.}\\
\end{eqnarray*}

For a selected policyholder, random variables $X_j$ are assumed to be iid for $j=1,\ldots,n$ because it is assumed that the policyholder's exposure to loss is not changing through time and $\mathrm{E}_{X}(\bar{X}|\theta)=\mathrm{E}_{X}(X_j|\theta)=\mu(\theta)$.  

If a policyholder is randomly chosen from the class and there is no loss information about the risk then the expected loss is $\mu=\mathrm{E}_{\Theta}(\mu(\theta))$ where the expectation is taken over all $\theta$'s in the class.  In this situation $Z=0$ and the expected loss is $\hat\mu(\theta)=\mu$ for the risk.  The quantity $\mu$ can also be written as $\mu=\mathrm{E}(X_j)$ or $\mu=\mathrm{E}(\bar{X})$ and is referred to as the overall mean, population mean, or collective mean.  Note that $\mathrm{E}(X_j)$ is evaluated with the `r Gloss('law of total expectation')`: $\mathrm{E}(X_j)=\mathrm{E_\Theta}[\mathrm{E_X}(X_j|\theta)]$.   


Although formula \@ref(eq:buhlcred) was introduced using experience rating as an example, the B&uuml;hlmann credibility model has wider application.  Suppose that a rating plan has multiple classes.  Credibility formula \@ref(eq:buhlcred) can be used to determine individual class rates.  The overall mean $\mu$ would be the average loss for all classes combined, $\bar{x}$ would be the experience for the individual class, and $\hat{\mu}(\theta)$ would be the estimated loss for the class. 


### Credibility *Z*, *EPV*, and *VHM* {#S:Sec1222}

When computing the credibility estimate $\hat{\mu}(\theta)=Z\bar{X}+(1-Z)\mu$, how much weight $Z$ should go to experience $\bar{X}$ and how much weight $(1-Z)$ to the overall mean $\mu$?  In B&uuml;hlmann credibility there are three factors that need to be considered:


1. How much variation is there in a single observation $X_j$ for a selected risk?  With $\bar{X}=(X_1+\cdots+X_n)/n$ and assuming that the observations are iid conditional on $\theta$, it follows that $\mathrm{Var}_{X}(\bar{X}|\theta)$ = $\mathrm{Var}_{X}(X_j|\theta)/n$.  For larger $\mathrm{Var}_{X}(\bar{X}|\theta)$ less credibility weight $Z$ should be given to experience $\bar{X}$.  The `r Gloss('Expected Value of the Process Variance')`, abbreviated $EPV$, is the expected value of $\mathrm{Var}_{X}(X_j|\theta$) across all risks:
$$
EPV = \mathrm{E}_{\Theta}(\mathrm{Var}_{X}(X_j|\theta)). 
$$
Because $\mathrm{Var}_{X}(\bar{X}|\theta)$ = $\mathrm{Var}_{X}(X_j|\theta)/n$ it follows that $\mathrm{E}_{\Theta}(\mathrm{Var}_{X}(\bar{X}|\theta))=EPV/n$.
2. How homogeneous is the population of risks whose experience was combined to compute the overall mean $\mu$?  If all the risks are similar in loss potential then more weight $(1-Z)$ would be given to the overall mean $\mu$ because $\mu$ is the average for a group of similar risks whose means $\mu(\theta)$ are not far apart.  The homogeneity or heterogeneity of the population is measured by the `r Gloss('Variance of the Hypothetical Means')` with abbreviation $VHM$:
$$
VHM=\mathrm{Var}_{\Theta}(\mathrm{E}_{X}(X_j|\theta))=\mathrm{Var}_{\Theta}(\mathrm{E}_{X}(\bar{X}|\theta)). 
$$
Note that we used $\mathrm{E}_{X}(\bar{X}|\theta)=\mathrm{E}_{X}(X_j|\theta)$ for the second equality.
3. How many observations $n$ were used to compute $\bar{X}$?  A larger sample would infer a larger $Z$.

**Example 12.2.3.** The number of claims $N$ in a year for a risk in a population has a Poisson distribution with mean $\lambda>0$.  The risk parameter $\lambda$ is uniformly distributed over the interval $(0,2)$.  Calculate the $EPV$ and $VHM$ for the population.

`r HideExample('11.2.3','Show Example Solution')`

`r SolnBegin()`  Random variable $N$ is Poisson with parameter $\lambda$ so $\mathrm{Var}(N|\lambda)=\lambda$.  The Expected Value of the Process variance is $EPV=\mathrm{E}(\mathrm{Var}(N|\lambda))$ = $\mathrm{E}(\lambda)=\int_{0}^{2}\lambda \frac{1}{2} d\lambda=1$.  The Variance of the Hypothetical Means is $VHM=\mathrm{Var}(\mathrm{E}(N|\lambda))$ = $\mathrm{Var}(\lambda)=\mathrm{E}(\lambda^2)-(\mathrm{E}(\lambda))^2$ = $\int_{0}^{2}\lambda^2 \frac{1}{2} d\lambda-(1)^2=\frac{1}{3}$.
`r SolnEnd()` 

</div>

*** 


The B&uuml;hlmann credibility formula includes values for $n$, $EPV$, and $VHM$:
\begin{equation}
Z=\frac{n}{n+K} \quad , \quad K =\frac{EPV}{VHM}. 
(\#eq:buhlZ) 
\end{equation}
If the $VHM$ increases then $Z$ increases.  If the $EPV$ increases then $Z$ gets smaller. Credibility $Z$ asymptotically approaches 1 as the number of observations $n$ goes to infinity.

If you multiply the numerator and denominator of the $Z$ formula by ($VHM$/$n$) then $Z$ can be rewritten as
$$
Z=\frac{VHM}{VHM+(EPV/n)} . 
$$
The number of observations $n$ is captured in the term ($EPV/n$). 

**Example 12.2.4.** The `r Gloss('law of total variance')` can be written as $\mathrm{Var}(Y)=\mathrm{E}(\mathrm{Var}[Y|X])+\mathrm{Var}(\mathrm{E}[Y|X])$. Show that $\mathrm{Var}(\bar{X})$ = $VHM + (EPV/n)$ and derive a formula for $Z$ in terms of $\bar{X}$.

`r HideExample('12.2.4','Show Example Solution')`

`r SolnBegin()` The quantity $\mathrm{Var}(\bar{X})$ is called the unconditional variance or the total variance of $\bar{X}$.  The law of total variance says 
$$
\mathrm{Var}(\bar{X})=\mathrm{E}_{\Theta}(\mathrm{Var}_{X}(\bar{X}|\theta))+\mathrm{Var}_{\Theta}(\mathrm{E}_{X}(\bar{X}|\theta)). 
$$
In bullet (1) at the beginning of this section we showed $\mathrm{E}_{\Theta}(\mathrm{Var}_{X}(\bar{X}|\theta))$ = $EPV/n$.  In bullet (2), $\mathrm{Var}_{\Theta}(\mathrm{E}_{X}(\bar{X}|\theta))=VHM$.  Reordering the right hand side gives $\mathrm{Var}(\bar{X})$ = $VHM +(EPV/n)$.  Another way to write the formula for credibility $Z$ is  $Z=\mathrm{Var}_{\Theta}(\mathrm{E}_{X}(\bar{X}|\theta))/\mathrm{Var}(\bar{X})$.  This implies $(1-Z)=\mathrm{E}_{\Theta}(\mathrm{Var}_{X}(\bar{X}|\theta))/\mathrm{Var}(\bar{X})$.
`r SolnEnd()` 

</div>

*** 


 The following long example and solution demonstrate how to compute the credibility-weighted estimate with frequency and severity data. 


**Example 12.2.5.** For any risk in a population the number of losses $N$ in a year has a Poisson distribution with parameter $\lambda$.  Individual loss amounts $X$ for a selected risk are independent of $N$ and are *iid* with exponential distribution $F(x)=1-e^{-x/\beta}$.  There are three types of risks in the population as shown below.  A risk was selected at random from the population and all losses were recorded over a five-year period.  The total amount of losses over the five-year period was 5,000.  Use B&uuml;hlmann credibility to estimate the annual expected aggregate loss for the risk.  
$$
\small{
\begin{array}{|c|c|c|c|}
\hline
\text{Risk } & \text{Percentage} & \text{Poisson} & \text{Exponential} \\
\text{Type} & \text{of Population} & \text{Parameter} & \text{Parameter} \\
\hline
A & 50\% & \lambda=0.5 & \beta=1000 \\
B & 30\% & \lambda=1.0 & \beta=1500 \\  
C & 20\% & \lambda=2.0 & \beta=2000 \\              
\hline
\end{array}
}
$$

`r HideExample('12.2.5','Show Example Solution')`

`r SolnBegin()`  Because individual loss amounts $X$ are exponentially distributed, $\mathrm{E}(X| \beta)=\beta$ and $\mathrm{Var}(X| \beta)=\beta^2$.  For aggregate loss $S=X_1+\cdots+X_N$, the mean is $\mathrm{E}(S)=\mathrm{E}(N)\mathrm{E}(X)$ and process variance is $\mathrm{Var}(S)=\mathrm{E}(N)\mathrm{Var}(X)+[\mathrm{E}(X)]^2 \mathrm{Var}(N)$.  

With Poisson frequency and exponentially distributed loss amounts, $\mathrm{E}(S| \lambda, \beta) = \lambda\beta$ and $\mathrm{Var}(S| \lambda, \beta$) = $\lambda\beta^2+\beta^2\lambda=2\lambda\beta^2$.  

Population mean $\mu$:  Risk means are $\mu$(A)=0.5(1000)=500; $\mu$(B)=1.0(1500)=1500; $\mu$(C)=2.0(2000)=4000; and  $\mu$=0.50(500)+0.30(1500)+0.20(4000)=1,500.

$\textbf{VHM}$:  $VHM$=$0.50(500-1500)^2+0.30(1500-1500)^2+0.20(4000-1500)^2$=1,750,000. 

$EPV$:  Process variances are $\sigma^2(A)=2(0.5)(1000)^2=1,000,000$; $\sigma^2(B)=2(1.0)(1500)^2=4,500,000$; $\sigma^2(C)=2(2.0)(2000)^2=16,000,000$; and $EPV$=0.50(1,000,000)+0.30(4,500,000)+0.20(16,000,000)=5,050,000.  
$\mathbf{\bar{X}}$:  $\bar{X}_5=5,000/5$=1,000.  

$\mathbf{K}$:  $K=5,050,000/1,750,000$=2.89.  

$\mathbf{Z}$:  There are five years of observations so $n=5$.  $Z=5/(5+2.89)$=0.63.  

$\boldsymbol{\hat{\mu}(\theta)}$:  $\hat{\mu}(\theta)=0.63(1,000)+(1-0.63)1,500=\boxed{\mathbf{1,185.00}}$.  

`r SolnEnd()` 

</div>

*** 

In real world applications of B&uuml;hlmann credibility the value of $K=EPV/VHM$ must be estimated.  Sometimes a value for $K$ is selected using judgment.  A smaller $K$ makes estimator $\hat{\mu}(\theta)$ more responsive to actual experience $\bar{X}$ whereas a larger $K$ produces a more stable estimate by giving more weight to $\mu$.  Judgment may be used to balance responsiveness and stability.  Section \@ref(S:Sec125) in this chapter will discuss methods for determining $K$ from data.


```{r child = './Quizzes/Quiz93.html', eval = QUIZ}
```



## Bayesian Inference and B&uuml;hlmann Credibility {#S:Sec123}

***

In this section, you learn how to:

* Calculate formulas for expected outcomes for beta-binomial and gamma-Poisson models using Bayes Theorem or B&uuml;hlmann credibility .
* Understand the connection between the Bayesian and B&uuml;hlmann estimates for conjugate families.

***

Chapter \@ref(ChBayes) presents `r Gloss('Bayesian inference and modeling')` and it is assumed that the reader is familiar with that material, in particular, Section \@ref(S:Sec93) which discusses conjugate families. This section will compare Bayesian inference with B&uuml;hlmann credibility and show connections between the two models.

First we will look at a Bayesian model.  Suppose a risk has $n$ observed losses $x_1, x_2, ..., x_n$. These losses will be represented by the vector $\mathbf{x} = (x_1, x_2, ..., x_n)$ which are realizations of the random variables $\mathbf{X} = (X_1, X_2, ..., X_n)$ which we will assume are iid.

A risk with risk parameter $\theta$ has expected loss $\mu(\theta)=\mathrm{E}_{X}(X|\theta)$. If the risk had losses $\mathbf{x}$ then $\mathrm{E}_{\Theta}(\mu(\theta)|\mathbf{x})$ is the conditional expectation of $\mu(\theta)$ given outcomes $\mathbf{x}$.  The expected loss is updated to reflect the observations.

The expectation $\mathrm{E}_{\Theta}(\mu(\theta)|\mathbf{x})$ can be calculated using the conditional density function $f_{X|\Theta=\theta}(x|\theta)$ and the posterior distribution $f_{\Theta|\mathbf{X}=\mathbf{x}}(\theta|\mathbf{x})$
\begin{eqnarray*}  
\mu(\theta)&=&\mathrm{E}_{\Theta}(X|\theta)=\int  xf_{X|\Theta=\theta}(x|\theta)dx \\
\mathrm{E}_{\Theta}(\mu(\theta)|\mathbf{x})&=&\int \mu(\theta) f_{\Theta|\mathbf{X}=\mathbf{x}}(\theta|\mathbf{x}) d\theta.
\end{eqnarray*}
The integrations are over the support of the distributions. The posterior distribution comes from `r Gloss('Bayes theorem')`
\begin{equation*} 
f_{\Theta|\mathbf{X}=\mathbf{x}}(\theta) = \frac{f_{\mathbf{X}|\Theta=\theta}(\mathbf{x})\, f_{\Theta}(\theta)}{f_{\mathbf{X}}(\mathbf{x})}.
\end{equation*}
The first function  $f_{\mathbf{X}|\Theta=\theta}(\mathbf{x})$ in the numerator is the likelihood function and the second term $f_{\Theta}(\theta)$ is the prior distribution.  The denominator $f_{\mathbf{X}}(\mathbf{x})$ is the joint density function for $n$ losses $\mathbf{x}=(x_1,\ldots,x_n)$.

Now we turn to the B&uuml;hlmann model. The B&uuml;hlmann credibility estimate for $\mathrm{E}_{\Theta}(\mu(\theta)|\mathbf{x})$ is $\hat{\mu}(\theta)=Z\bar{x}+(1-Z)\mu$. This model requires  credibility $Z$ and collective mean $\mu$ which can be computed from the distributions used in the Bayesian model described above, if the distributions are known.

**Example 12.3.1.** Using $n$, conditional density function $f_{X|\Theta=\theta}(x|\theta)$, and prior distribution $f_{\Theta}(\theta)$, calculate credibility $Z$ and collective mean $\mu$ for the B&uuml;hlmann credibility estimate $\hat{\mu}(\theta)$.

`r HideExample('11.3.1','Show Example Solution')`

`r SolnBegin()` The collective mean is
\begin{equation*}  
\mu=\int \int x f_{X|\Theta=\theta}(x|\theta) f_{\Theta}(\theta) dx d\theta.
\end{equation*}
The Variance of the Hypothetical Means (VHM) is calculated as follows
\begin{eqnarray*} 
\mu(\theta) &=&\int x f_{X|\Theta=\theta}(x|\theta) dx , \\
\mathrm{VHM}&=&\int (\mu(\theta)-\mu)^{2} f_{\Theta}(\theta) d\theta.
\end{eqnarray*}
The Expected Value of the Process Value (EPV) is calculated as follows
\begin{eqnarray*}
\mathrm{Var}_{X}(x|\theta)&=&\int (x-\mu(\theta))^2 f_{X|\Theta=\theta}(x|\theta) dx , \\
\mathrm{EPV}          &=&\int \mathrm{Var}_{X}(x|\theta) f_{\Theta}(\theta) d\theta.
\end{eqnarray*}
The credibility is $Z = n/(n+K)$ with $K=EPV/VHM$.
`r SolnEnd()` 

</div>

*** 

### Beta-Binomial Model {#S:Sec1231}

Section \@ref(S:Sec931) of the chapter `r Gloss('Bayesian Inference and Modeling')` analyzes the beta-binomial model.

The number of successes $x$ in $m$ Bernoulli trials with unknown probability of success $q$ is given by the binomial distribution
\begin{equation*}
p_{X|Q=q}(x) = \binom{m}{x} q^x (1-q)^{m-x}, \quad x \in \{0,1,...,m\}.
\end{equation*}
The probability of success $q$ is modeled with the conjugate prior for the binomial distribution: the beta distribution with parameters $a$ and $b$. The pdf of the beta distribution is
$$
f_{Q}(q) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} q^{a-1} (1-q)^{b-1}, \quad q \in [0,1].
$$
Given $x$ successes in $m$ Bernoulli trials the posterior distribution for $q$ was shown in \@ref(S:Sec931) to be
$$
f_{Q|X=x}(q) = \frac{\Gamma(a+b+m)}{\Gamma(a+x)\Gamma(b+m-x)} q^{a+x-1} (1-q)^{b+m-x-1},
$$
which is a beta distribution with parameters $a+x$ and $b+m-x$. 

The mean for the beta distribution with parameters $a$ and $b$ is $\mathrm{E}(Q)=a/(a+b)$.  Given $x$ successes in $m$ trials in the beta-binomial model the mean of the posterior distribution is
\begin{equation*} 
\mathrm{E}_{Q}(Q|x)=\frac{a+x}{a+b+m}.  
\end{equation*}   
The B&uuml;hlmann credibility estimate for $\mathrm{E}_{Q}(Q|x)$ exactly matches the Bayesian estimate as demonstrated in the following example.

**Example 12.3.2**. The probability that a coin toss will yield heads is $q$.  The prior distribution for probability $q$ is beta with parameters $a$ and $b$. On $m$ tosses of the coin there were exactly $x$ heads.  Use  B&uuml;hlmann credibility to estimate the expected value of $q$.

`r HideExample('12.3.2','Show Example Solution')`

`r SolnBegin()` Define random variables $Y_j$ such that $Y_j=1$ if the $j^{th}$ coin toss is heads and $Y_j=0$ if tails for $j=1,\ldots, m$.  Random variables $Y_j$ are iid conditional on $q$ with Pr$(Y=1|q)=q$ and Pr$(Y=0|q)=1-q$  The number of heads in $m$ tosses can be represented by the random variable $X=Y_1+\cdots+Y_m$.  

We want to estimate $q=E(Y_j|X=x)$ using Buhlmann credibility: $\hat{q} = Z\bar{x} +(1-Z)\mu$.  The overall mean is $\mu=\mathrm{E}(\mathrm{E}(Y_j|Q))$ = $\mathrm{E}(Q)=a/(a+b)$.  The sample mean is $\bar{x}=x/m$.  

The credibility is $Z=m/(m+K)$ and $K=EPV/VHM$.  With $\mathrm{Var}(Y_j|q)=q(1-q)$ it follows that $EPV = \mathrm{E}(\mathrm{Var}[Y_j|Q])$ = $\mathrm{E}(Q(1-Q)$).  Because $\mathrm{E}(Y_j|q)=q$ then $VHM=\mathrm{Var}((\mathrm{E}(Y_j|Q))=\mathrm{Var}(Q)$.  For the beta distribution
$$ 
\mathrm{E}(Q)=\frac{a}{a+b}, \mathrm{E}(Q^2)=\frac{a(a+1)}{(a+b)(a+b+1)}, \textrm{ and } \mathrm{Var}(Q)=\frac{ab}{(a+b)^2(a+b+1)}.
$$
Parameter $K=EPV/VHM$=$[\mathrm{E}(Q)-\mathrm{E}(Q^2)]/\mathrm{Var}(Q)$.  With some algebra this reduces to $K=a+b$.  The Buhlmann credibility-weighted estimate is
\begin{align*}
  \hat{q} &= \frac{m}{m+a+b}\left(\frac{x}{m}\right)+\left(1-\frac{m}{m+a+b}\right)\frac{a}{a+b} \\
  \hat{q} & =\frac{a+x}{a+b+m}\\
\end{align*}
which is the same as the Bayesian posterior mean.
`r SolnEnd()` 

</div>

### Gamma-Poisson Model {#S:Sec1232}

The chapter `r Gloss('Bayesian Inference and Modeling')` also analyzes the gamma-Poisson conjugate family.  The results are summarized below.

Let $\mathbf{X} = (X_1, X_2, ..., X_n)$ be a sample of iid Poisson random variables with
$$
p_{X_i|\Lambda=\lambda}(x_i) = \frac{\lambda^{x_i}\, e^{-\lambda}}{x_i!}, \quad x_i \in \mathbb{R}_+ .
$$
Define the prior distribution for $\Lambda$ to be gamma with parameters $\alpha$ and $\theta$,
$$
f_{\Lambda}(\lambda) = \frac{1}{\Gamma(\alpha)\theta^{\alpha}} \lambda^{\alpha-1} \, e^{-\frac{\lambda}{\theta}}, \quad \lambda \in \mathbb{R}_+.
$$
Given a sample of $n$ observations  $\mathbf{x} = (x_1, x_2, ..., x_n)$, the posterior distribution of $\Lambda$ is
$$
f_{\Lambda|\mathbf{X}=\mathbf{x}}(\lambda) = \frac{1}{\Gamma(\alpha+x)\left(\frac{\theta}{n\theta+1} \right)^{\alpha+x}} \lambda^{\alpha+x-1} \, e^{-\frac{\lambda\,(n\theta+1)}{\theta}},
$$
where $x = \sum_{i=1}^n x_i$, which is a gamma distribution with parameters $\alpha+x$ and $\tfrac{\theta}{n\theta+1}$. 

We are going to make a minor change to the formulas above. Instead of a  scale parameter $\theta$, we will substitute a rate parameter $\beta=1/\theta$. The posterior distribution becomes
$$
f_{\Lambda|\mathbf{X}=\mathbf{x}}(\lambda) = \frac{(\beta+n)^{(\alpha+x)}}{\Gamma(\alpha+x)} \lambda^{\alpha+x-1} \, e^{-\lambda(\beta+n)}.
$$
The posterior distribution is gamma and the expected value for $\Lambda$ given observations $\mathbf{x}$ is easy to calculate: 
\begin{equation*}  
\mathrm{E}_{\Lambda}(\Lambda|x_1,\ldots,x_n) = \frac{\alpha+x}{\beta+n}.
\end{equation*}
Prior to collecting a sample, $\mathrm{E}(\Lambda)=\alpha/\beta$ using parameters from the prior distribution.  

The B&uuml;hlmann credibility model will give the same result as seen in the following example.

**Example 12.3.3** The number of claims X each year for a risk has a Poisson distribution $p(x)=\lambda^{x} e^{-\lambda} /x!$. Each risk in a class has a constant risk parameter $\lambda$.  Parameter $\lambda$ is gamma distributed across the class with pdf $f(\lambda) = \beta^{\alpha}\lambda^{\alpha-1}e^{-\lambda\beta}/\Gamma(\alpha)$. A risk was selected at random from the population and observed for $n$ years. The claims counts were $\mathbf{x} = (x_1, x_2, ..., x_n)$. Use B&uuml;hlmann credibility to calculate the expected value of $\lambda$ for the selected risk.

`r HideExample('11.3.3','Show Example Solution')`

`r SolnBegin()` The variance for a Poisson distribution with parameter $\lambda$ is $\lambda$ so $EPV=\mathrm{E}(\mathrm{Var}(X|\lambda))=\mathrm{E}(\lambda)=\alpha/\beta$. The mean number of claims per year for the risk is $\lambda$ so $VHM=\mathrm{Var}(\mathrm{E}(X|\lambda))$ = $\mathrm{Var}(\lambda)=\alpha/\beta^2$.  The credibility parameter is $K=EPV/VHM$ = $(\alpha/\beta)/(\alpha/\beta^2)=\beta$.  The overall mean is $\mathrm{E}(\mathrm{E}(X|\lambda))=\mathrm{E}(\lambda)=\alpha/\beta$.  Letting $x=\sum_{j=1}^{n}x_j$, the sample mean is $\bar{x}=x/n$.  The credibility-weighted estimate for the expected number of claims for the risk is
$$
\hat{\mu}=\frac{n}{n+\beta}\bar{x} +\left(1-\frac{n}{n+\beta}\right)\frac{\alpha}{\beta}=\frac{\alpha+x}{\beta+n}. 
$$
`r SolnEnd()` 

</div>

We will leave it to the reader to compare the Bayesian and B&uuml;hlmann models for the normal-normal conjugate family.


*** 

### Exact Credibility {#S:Sec1233}

As demonstrated in the prior section, the B&uuml;hlmann credibility estimates for the beta-binomial and gamma-Poisson models exactly match the Bayesian analysis results.  The term `r Gloss('exact credibility')` is applied in these situations.  Exact credibility may occur if the probability distribution for $X_j$ is in the linear exponential family and the prior distribution is a conjugate prior.  Besides these two models, examples of exact credibility also include Gamma-Exponential and Normal-Normal models. 

If the conditional mean $\mathrm{E}_{\Theta}(\mu(\theta)|X_1,...,X_n)$ is linear in the mean of the observations, then the B&uuml;hlmann credibility estimate will coincide with the Bayesian estimate. More information about exact credibility can be found in [@BuhlmannGisler2005], [@klugman2012], and [@Tse2009].



## B&uuml;hlmann-Straub Credibility {#S:Sec124}

***

In this section, you learn how to:

* Compute a credibility-weighted estimate for the expected loss for a risk or group of risks using the B&uuml;hlmann-Straub model.
* Determine the credibility $Z$ assigned to observations.
* Calculate required values including the Expected Value of the Process Variance ($EPV$), Variance of the Hypothetical Means ($VHM$) and collective mean $\mu$.
* Recognize situations when the B&uuml;hlmann-Straub model is appropriate.

***

With standard B&uuml;hlmann credibility as described in the prior section, losses $X_1,\ldots,X_n$ arising from a selected policyholder are assumed to be iid.  If the subscripts indicate year 1, year 2 and so on up to year $n$, then the iid assumption means that the policyholder has the same exposure to loss every year.  For commercial insurance this assumption is frequently violated.

Consider a commercial policyholder that uses a fleet of vehicles in its business.  In year 1 there are $m_1$ vehicles in the fleet, $m_2$ vehicles in year 2, .., and $m_n$ vehicles in year $n$.  The exposure to loss from ownership and use of this fleet is not constant from year to year.  The annual losses for the fleet are not iid.  

Define $Y_{jk}$ to be the loss for  the $k^{th}$ vehicle in the fleet for year $j$.  Then, the total losses for the fleet in year $j$ are $Y_{j1}+\cdots+Y_{jm_j}$ where we are adding up the losses for each of the $m_j$ vehicles.  In the B&uuml;hlmann-Straub model it is assumed that random variables $Y_{jk}$ are iid across all vehicles and years for the policyholder.  With this assumption the means $\mathrm{E}_{Y}(Y_{jk}|\theta)=\mu(\theta)$ and variances $\mathrm{Var}_{Y}(Y_{jk}|\theta)=\sigma^2(\theta)$ are the same for all vehicles and years.  The quantity $\mu(\theta)$ is the expected loss and $\sigma^2(\theta)$ is the variance in the loss for one year for one vehicle for a policyholder with risk parameter $\theta$.

If $X_j$ is the average loss per unit of exposure in year $j$, $X_j=(Y_{j1}+\cdots+Y_{jm_j})/m_j$, then $\mathrm{E}_{Y}(X_j|\theta)=\mu(\theta)$ and $\mathrm{Var}_{Y}(X_j|\theta)=\sigma^2(\theta)/m_j$ for a policyholder with risk parameter $\theta$.  Note that we used the fact that the $Y_{jk}$ are iid for a given policyholder.  The average loss per vehicle for the entire $n$-year period is
\begin{equation*}
\bar{X}= \frac{1}{m} \sum_{j=1}^{n} m_j X_{j} \quad , \quad  m=\sum_{j=1}^{n}  m_j. 
\end{equation*}
It follows that $\mathrm{E}_{Y}(\bar{X}|\theta)=\mu(\theta)$ and $\mathrm{Var}_{Y}(\bar{X}|\theta)=\sigma^2(\theta)/m$ where $\mu(\theta)$ and $\sigma^2(\theta)$ are the mean and variance for a single vehicle for one year for the policyholder.


**Example 12.4.1.** Prove that $\mathrm{Var}_{Y}(\bar{X}|\theta)=\sigma^2(\theta)/m$ for a risk with risk parameter $\theta$.

`r HideExample('12.4.1','Show Example Solution')`

`r SolnBegin()`  
\begin{eqnarray*}
\mathrm{Var}_{Y}(\bar{X}|\theta)&=&\mathrm{Var}_{Y}\left(\frac{1}{m} \sum_{j=1}^{n} m_j X_j|\theta \right)\\
                                  &=&\frac{1}{m^2}\sum_{j=1}^{n} \mathrm{Var}_{Y}(m_j X_{j}|\theta)=\frac{1}{m^2}\sum_{j=1}^{n} m_j^2 \mathrm{Var}_{Y}(X_j|\theta)\\
                                  &=&\frac{1}{m^2}\sum_{j=1}^{n} m_j^2 (\sigma^2(\theta)/m_j)=\frac{\sigma^2(\theta)}{m^2}\sum_{j=1}^{n} m_j=\sigma^2(\theta)/m.\\
\end{eqnarray*}
`r SolnEnd()` 

</div>

*** 

The `r Gloss("Buhlmann-Straub credibility")` estimate is:
\begin{equation}\hat{\mu}(\theta)=Z\bar{x}+(1-Z)\mu 
(\#eq:bscred) 
\end{equation}
with
\begin{eqnarray*} 
\theta&=&\textrm{a risk parameter that identifies a policyholder's risk level}\\
\hat{\mu}(\theta)&=&\textrm{estimated expected loss for one exposure for the policyholder}\\
 & & \textrm{with loss experience } \bar{X}\\
\bar{x}&=& \frac{1}{m} \sum_{j=1}^{n} m_j x_j \textrm{ is the average loss per exposure for $m$ exposures.}\\
 & & \textrm{$x_j$ is the average loss per exposure and $m_j$ is the number of exposures in year $j$.} \\
Z&=&\textrm{credibility assigned to $m$ exposures } \\
 \mu&=&\textrm{expected loss for one exposure for randomly chosen}\\
 & & \textrm{ policyholder from population.}\\
\end{eqnarray*}

Note that $\hat{\mu}(\theta)$ is the estimator for the expected loss for one exposure.  If the policyholder has $m_j$ exposures then the expected loss is $m_j\hat{\mu}(\theta)$.

In Example 12.2.4, it was shown that $Z=\mathrm{Var}_{\Theta}(\mathrm{E}_{X}(\bar{X}|\theta))/\mathrm{Var}(\bar{X})$ where $\bar{X}$ is the average loss for $n$ observations.  In equation \@ref(eq:bscred) the $\bar{X}$ is the average loss for $m$ exposures and the same $Z$ formula can be used:
$$
Z=\frac{\mathrm{Var}_{\Theta}(\mathrm{E}_{Y}(\bar{X}|\theta))}{\mathrm{Var}(\bar{X})}=
\frac{\mathrm{Var}_{\Theta}(\mathrm{E}_{Y}(\bar{X}|\theta))}{\mathrm{E}_{\Theta}(\mathrm{Var}_{Y}(\bar{X}|\theta))+\mathrm{Var}_{\Theta}(\mathrm{E}_{Y}(\bar{X}|\theta))}. 
$$
(Note that $X_{j}$ is a sum of $Y_{jk}$'s and $\bar{X}$ is an average of $Y_{jk}$'s.) The denominator was expanded using the `r Gloss('law of total variance')`.  As noted above $\mathrm{E}_{Y}(\bar{X}|\theta)=\mu(\theta)$ so $\mathrm{Var}_{\Theta}(\mathrm{E}_{Y}(\bar{X}|\theta))=\mathrm{Var}_{\Theta}(\mu(\theta))=VHM$.
  Because $\mathrm{Var}_{Y}(\bar{X}|\theta)=\sigma^2(\theta)/m$ it follows that $\mathrm{E}_{\Theta}(\mathrm{Var}_{Y}(\bar{X}|\theta))=\mathrm{E}_{\Theta}(\sigma^2(\theta))/m$ = $EPV/m$.  Making these substitutions and using a little algebra gives
\begin{equation}
Z=\frac{m}{m+K} \quad , \quad K =\frac{EPV}{VHM}. 
(\#eq:bsZ) 
\end{equation}
This is the same $Z$ as for B&uuml;hlmann credibility except number of exposures $m$ replaces number of years or observations $n$.  


**Example 12.4.2.**  A commercial automobile policyholder had the following exposures and claims over a three-year period:
$$
\small{
\begin{array}{|c|c|c|}
\hline
\text{Year} & \text{Number of Vehicles} & \text{Number of Claims} \\
\hline
1 &   9 &  5  \\
2 & 12 &  4  \\  
3 & 15 &  4  \\              
\hline
\end{array}
}
$$

* The number of claims in a year for each vehicle in the policyholder's fleet is Poisson distributed with the same mean (parameter) $\lambda$.
* Parameter $\lambda$ is distributed among the policyholders in the population with *pdf* $f(\lambda)=6\lambda(1-\lambda)$ with $0<\lambda<1$.

The policyholder has 18 vehicles in its fleet in year 4.  Use B&uuml;hlmann-Straub credibility to estimate the expected number of policyholder claims in year 4.

`r HideExample('12.4.2','Show Example Solution')`

`r SolnBegin()`  The expected number of claims for one vehicle for a randomly chosen policyholder is $\mu=\mathrm{E}(\lambda)=\int_{0}^{1} \lambda[6\lambda(1-\lambda)] d\lambda=1/2$.  The average number of claims per vehicle for the policyholder is $\bar{X}$=13/36.  The expected value of the process variance for a single vehicle is $EPV=\mathrm{E}(\lambda)=1/2$.  

The variance of the hypothetical means across policyholders is $VHM = \mathrm{Var}(\lambda)$ = $\mathrm{E}(\lambda^2$)-$(\mathrm{E}(\lambda))^2=\int_{0}^{1} \lambda^2[6\lambda(1-\lambda)] d\lambda-(1/2)^2=(3/10)-(1/4)=(6/20)-(5/20)=1/20$.  So, $K=EPV/VHM$=(1/2)/(1/20)=10.  The number of exposures in the experience period is $m=9+12+15=36$.  The credibility is $Z=36/(36+10)=18/23$.  

The credibility-weighted estimate for the number of claims for one vehicle is $\hat{\mu}(\theta)=Z\bar{X}+(1-Z)\mu$=(18/23)(13/36)+(5/23)(1/2)=9/23.  With 18 vehicles in the fleet in year 4 the expected number of claims is 18(9/23)=162/23=7.04 .
`r SolnEnd()` 

</div>

*** 


## Estimating Credibility Parameters {#S:Sec125}

***

In this section, you learn how to:

* Perform nonparametric estimation with the B&uuml;hlmann and B&uuml;hlmann-Straub credibility models.
* Identify situations when semiparametric estimation is appropriate.
* Use data to approximate the $EPV$ and $VHM$.

***

The examples in this chapter have provided assumptions for calculating credibility parameters.  In actual practice the actuary must use real world data and judgment to determine credibility parameters.   


### Nonparametric Estimation for B&uuml;hlmann and B&uuml;hlmann-Straub Models

Bayesian analysis as described previously requires assumptions about a prior distribution and likelihood.  It is possible to produce estimates without these assumptions and these methods are often referred to as `r Gloss('empirical Bayes methods')`.  B&uuml;hlmann and B&uuml;hlmann-Straub credibility with parameters estimated from the data are included in the category of empirical Bayes methods.


**B&uuml;hlmann Model**. First we will address the simpler B&uuml;hlmann model.  Assume that there are $r$ risks in a population.  For risk $i$ with risk parameter $\theta_i$ the losses for $n$ periods are $X_{i1},\ldots, X_{in}$.  The losses for a given risk are *iid* across periods as assumed in the B&uuml;hlmann model.  For risk $i$ the sample mean is $\bar{X}_i=\sum_{j=1}^{n}X_{ij}/n$ and the unbiased sample process variance is $s_i^2=\sum_{j=1}^{n}(X_{ij}-\bar{X}_i)^2/(n-1)$.  An unbiased estimator for the $EPV$ can be calculated by taking the average of $s_i^2$ for the $r$ risks in the population:
\begin{equation}  
\widehat{EPV}=\frac{1}{r}\sum_{i=1}^{r} s_i^2 = \frac{1}{r(n-1)} \sum_{i=1}^{r} \sum_{j=1}^{n}(X_{ij}-\bar{X}_i)^2 .
(\#eq:EPV-estimate)
\end{equation}
The individual risk means $\bar{X}_i$ for $i=1,\ldots, r$ can be used to estimate the $VHM$.  An unbiased estimator of Var($\bar{X}_i$) is 
\begin{equation*} 
\widehat{\mathrm{Var}}(\bar{X}_i)=\frac{1}{r-1} \sum_{i=1}^{r}(\bar{X}_i-\bar{X})^2 \textrm{  and  }  \bar{X}=\frac{1}{r}\sum_{i=1}^{r} \bar{X}_i,
\end{equation*}
but Var($\bar{X}_i$) is not the $VHM$.  The total variance formula or *unconditional variance* formula is
$$ 
\mathrm{Var}(\bar{X}_i)=\mathrm{E}_{X}(\mathrm{Var}_{\Theta}(\bar{X}_i|\theta_i))+\mathrm{Var}_{\Theta}(\mathrm{E}_{X}(\bar{X}_i|\theta_i)).
$$
The $VHM$ is the second term on the right because $\mu(\theta_i)=\mathrm{E}_{X}(\bar{X}_i|\theta_i)$ is the hypothetical mean for risk $i$.  So,
\begin{equation*} 
VHM= \mathrm{Var}(\bar{X}_i) - \mathrm{E}_{\Theta}(\mathrm{Var}_{X}(\bar{X}_i|\theta_i)).
\end{equation*} 
As discussed previously in Section \@ref(S:Sec1222), $EPV/n$ = $\mathrm{E}_{\Theta}(\mathrm{Var}_{X}[\bar{X}_i|\theta_i])$ and using the above estimators gives an estimator for the $VHM$:
\begin{equation} 
\widehat{VHM} = \frac{1}{r-1} \sum_{i=1}^{r}(\bar{X}_i-\bar{X})^2 - \frac{\widehat{EPV}}{n} .
(\#eq:VHM-estimate)
\end{equation} 
Although the expected loss for a risk with parameter $\theta_i$ is $\mu(\theta_i)$=$\mathrm{E}_{X}(\bar{X}_i|\theta_i$), the variance of the sample mean $\bar{X}_i$ is greater than or equal to the variance of the hypothetical means: $\mathrm{Var}(\bar{X}_i)\geq\mathrm{Var}(\mu(\theta_i)$).  The variance in the sample means $\mathrm{Var}(\bar{X}_i$) includes both the variance in the hypothetical means plus a process variance term.

In some cases formula \@ref(eq:VHM-estimate) can produce a negative value for $\widehat{VHM}$ because of the subtraction of $\widehat{EPV}/n$, but a variance cannot be negative.    The process variance within risks is so large that it overwhelms the measurement of the variance in means between risks.  In this case we cannot use this method to determine the values needed for B&uuml;hlmann credibility.


**Example 12.5.1.** Two policyholders had claims over a three-year period as shown in the table below.  Estimate the expected number of claims for each policyholder using B&uuml;hlmann credibility and calculating necessary parameters from the data.
$$
\small{
\begin{array}{|c|c|c|}
\hline
\text{Year} & \text{Risk A} & \text{Risk B} \\
\hline
1 & 0 &  2 \\
2 & 1 &  1  \\  
3 & 0 &  2  \\              
\hline
\end{array}
}
$$

`r HideExample('12.5.1','Show Example Solution')`

`r SolnBegin()`  $\bar{x}_A=\frac{1}{3}(0+1+0)=\frac{1}{3}$, $\bar{x}_B=\frac{1}{3}(2+1+2)=\frac{5}{3}$ 

$\bar{x}=\frac{1}{2}(\frac{1}{3}+\frac{5}{3})=1$

$s_A^2=\frac{1}{3-1}\left[(0-\frac{1}{3})^2+(1-\frac{1}{3})^2+(0-\frac{1}{3})^2\right]=\frac{1}{3}$  

$s_B^2=\frac{1}{3-1}\left[(2-\frac{5}{3})^2+(1-\frac{5}{3})^2+(2-\frac{5}{3})^2\right]=\frac{1}{3}$ 

$\widehat{EPV}=\frac{1}{2}\left(\frac{1}{3}+\frac{1}{3}\right)=\frac{1}{3}$ 

$\widehat{VHM}=\frac{1}{2-1}\left[(\frac{1}{3}-1)^2+(\frac{5}{3}-1)^2\right]-\frac{1/3}{3}=\frac{7}{9}$  

$K=\frac{1/3}{7/9}=\frac{3}{7}$ 

$Z=\frac{3}{3+(3/7))}=\frac{7}{8}$

$\hat{\mu}_A=\frac{7}{8}\left(\frac{1}{3}\right)+(1-\frac{7}{8})1=\frac{5}{12}$

$\hat{\mu}_B=\frac{7}{8}\left(\frac{5}{3}\right)+(1-\frac{7}{8})1=\frac{19}{12}$  

`r SolnEnd()` 

</div>

*** 

**Example 12.5.2.**
Two policyholders had claims over a three-year period as shown in the table below.  Calculate the nonparametric estimate for the $VHM$.
 
$$
\small{
\begin{array}{|c|c|c|}
\hline
\text{Year} & \text{Risk A} & \text{Risk B} \\
\hline
1 & 3 &  3 \\
2 & 0 &  0  \\  
3 & 0 &  3  \\              
\hline
\end{array}
}
$$

`r HideExample('15.5.2','Show Example Solution')`

`r SolnBegin()`  $\bar{x}_A=\frac{1}{3}(3+0+0)=1$,  $\bar{x}_B=\frac{1}{3}(3+0+3)=2$ 

$\bar{x}=\frac{1}{2}(1+2)=\frac{3}{2}$  

$s_A^2=\frac{1}{3-1}\left[(3-1)^2+(0-1)^2+(0-1)^2\right]=3$  

$s_B^2=\frac{1}{3-1}\left[(3-2)^2+(0-2)^2+(3-2)^2\right]=3$  

$\widehat{EPV}=\frac{1}{2}(3+3)=3$  

$\widehat{VHM}=\frac{1}{2-1}\left[(1-\frac{3}{2})^2+(2-\frac{3}{2})^2\right]-\frac{3}{3}=-\frac{1}{2}.$  

The process variance is so large that it is not possible to estimate the $VHM$. 
`r SolnEnd()` 


</div>

*** 

**B&uuml;hlmann-Straub Model**  Empirical formulas for $EPV$ and $VHM$ in the B&uuml;hlmann-Straub model are more complicated because a risk's number of exposures can change from one period to another.  Also, the number of experience periods does not have to be constant across the population.  First some definitions:

* $X_{ij}$ is the losses per exposure for risk $i$ in period $j$.  Losses can refer to number of claims or amount of loss.  There are $r$ risks so $i=1,\ldots,r$.
* $n_i$ is the number of observation periods for risk $i$
* $m_{ij}$ is the number of exposures for risk $i$ in period $j$ for $j=1,\ldots,n_i$


Risk $i$ with risk parameter $\theta_i$ has $m_{ij}$ exposures in period $j$ which means that the losses per exposure random variable can be written as $X_{ij}=(Y_{i1}+\cdots+Y_{im_{ij}})/m_{ij}$.  Random variable $Y_{ik}$ is the loss for one exposure.  For risk $i$ losses $Y_{ik}$ are iid with mean $\mathrm{E}_{Y}(Y_{ik}|\theta_{i})=\mu(\theta_i)$ and process variance $\mathrm{Var}_{Y}(Y_{ik}|\theta_{i}) =\sigma^2(\theta_{i})$.  It follows that $\mathrm{Var}_{Y}(X_{ij}|\theta_{i})$ = $\sigma^2(\theta_i)/m_{ij}$.  

Two more important definitions are:

* $\bar{X}_i=\frac{1}{m_i}\sum_{j=1}^{n_i} m_{ij}X_{ij}$  with  $m_i = \sum_{j=1}^{n_i} m_{ij}$.  $\bar{X}_i$ is the average loss per exposure for risk $i$ for all observation periods combined.
* $\bar{X}=\frac{1}{m}\sum_{i=1}^{r} m_i \bar{X}_i$  with $m=\sum_{i=1}^r m_i$.  $\bar{X}$ is the average loss per exposure for all risks for all observation periods combined.

An unbiased estimator for the process variance $\sigma^2(\theta_i)$ of one exposure for risk $i$ is
\begin{equation*}  
{s_i}^2=\frac{\sum_{j=1}^{n_i} m_{ij}(X_{ij}-\bar{X}_i)^2}{n_i-1}. \end{equation*}
The weights $m_{ij}$ are applied to the squared differences because the $X_{ij}$ are the averages of $m_{ij}$ exposures.  The weighted average of the sample variances ${s_i}^2$ for each risk $i$ in the population with weights proportional to the number of $(n_i-1)$ observation periods will produce the expected value of the process variance ($EPV$) estimate
\begin{equation*}  
\widehat{EPV}=\frac{\sum_{i=1}^r  (n_i-1){s_i}^2}{\sum_{i=1}^r (n_i-1)}=\frac{\sum_{i=1}^r \sum_{j=1}^{n_i} m_{ij}(X_{ij}-\bar{X}_i)^2}{\sum_{i=1}^r (n_i-1)}.     
\end{equation*}
The quantity $\widehat{EPV}$ is an unbiased estimator for the expected value of the process variance of one exposure for a risk chosen at random from the population.

To calculate an estimator for the variance in the hypothetical means ($VHM$) the squared differences of the individual risk sample means $\bar{X}_i$ and population mean $\bar{X}$ are used.  An unbiased estimator for the $VHM$ is
\begin{equation*}  
\widehat{VHM}=\frac{\sum_{i=1}^r m_i(\bar{X}_i-\bar{X})^2 - (r-1)\widehat{EPV}}{m-\frac{1}{m}\sum_{i=1}^r m_i^2}.  
\end{equation*}
This complicated formula is necessary because of the varying number of exposures.  Proofs that the $EPV$ and $VHM$ estimators shown above are unbiased can be found in several references mentioned at the end of this chapter including [@BuhlmannGisler2005], [@klugman2012], and [@Tse2009].


**Example 12.5.3.** Two policyholders had claims shown in the table below.  Estimate the expected number of claims per vehicle for each policyholder using B&uuml;hlmann-Straub credibility and calculating parameters from the data.

$$
\small{
\begin{array}{|c|c|c|c|c|c|}
\hline
\text{Policyholder} &  & \text{Year 1} & \text{Year 2} & \text{Year 3} & \text{Year 4} \\
\hline
\text{A} & \text{Number of claims} & 0 & 2 & 2 & 3 \\
\hline
\text{A} & \text{Insured vehicles} &  1 & 2 & 2 & 2\\  
\hline
 & & & & & \\
\hline
\text{B} & \text{Number of claims} & 0 & 0 & 1 & 2\\    
\hline 
\text{B} & \text{Insured vehicles} &  0 & 2 & 3 & 4\\      
\hline
\end{array}
}
$$

`r HideExample('12.5.3','Show Example Solution')`

`r SolnBegin()`  $\bar{x}_A=\frac{0+2+2+3}{1+2+2+2}=1$  

$\bar{x}_B=\frac{0+1+2}{2+3+4}=\frac{1}{3}$ 

$\bar{x}=\frac{7(1)+9(1/3)}{7+9}=\frac{5}{8}$  

$s_A^2=\frac{1}{4-1}\left[1(0-1)^2+2(1-1)^2+2(1-1)^2+2(\frac{3}{2}-1)^2\right]=\frac{1}{2 }$  

$s_B^2=\frac{1}{3-1}\left[2(0-\frac{1}{3})^2+3(\frac{1}{3}-\frac{1}{3})^2+4(\frac{1}{2}-\frac{1}{3})^2\right]=\frac{1}{6}$  

$\widehat{EPV}=\left[3\left(\frac{1}{2}\right)+2\left(\frac{1}{6}\right)\right]/(3+2)=\frac{11}{30}=0.3667$  

$\widehat{VHM}=\left[(7(1-\frac{5}{8})^2+9(\frac{1}{3}-\frac{5}{8})^2-(2-1)\frac{11}{30}\right]/\left[16-\left(\frac{1}{16}\right)(7^2+9^2)\right]=0.1757$  

$K=\frac{0.3667}{0.1757}=2.0871$  

$m_A=7$,  $m_B=9$  

$Z_A=\frac{7}{7+2.0871}=0.7703$,      $Z_B=\frac{9}{9+2.0871}=0.8118$    

$\hat{\mu}_A=0.7703(1)+(1-0.7703)(5/8)=0.9139$  

$\hat{\mu}_B=0.8118(1/3)+(1-0.8118)(5/8)=0.3882 .$ 
`r SolnEnd()` 

</div>

*** 

### Semiparametric Estimation for B&uuml;hlmann and B&uuml;hlmann-Straub Models

In the prior section on `r Gloss('nonparametric estimation')`, there were no assumptions about the distribution of the losses per exposure $X_{ij}$.  Assuming that the $X_{ij}$ have a particular distribution and using properties of the distribution along with the data to determine credibility parameters is referred to as `r Gloss('semiparametric estimation')`.

An example of semiparametric estimation would be the assumption of a Poisson distribution when estimating claim frequencies.  The Poisson distribution has the property that the mean and variance are identical and this property can simplify calculations.   The following simple example comes from the prior section but now includes a Poisson assumption about claim frequencies.


**Example 12.5.4.** Two policyholders had claims over a three-year period as shown in the table below.  Assume that the number of claims for each risk has a Poisson distribution.  Estimate the expected number of claims for each policyholder using B&uuml;hlmann credibility and calculating necessary parameters from the data.
$$
\small{
\begin{array}{|c|c|c|}
\hline
\text{Year} & \text{Risk A} & \text{Risk B} \\
\hline
1 & 0 &  2 \\
2 & 1 &  1  \\  
3 & 0 &  2  \\              
\hline
\end{array}
}
$$

`r HideExample('12.5.4','Show Example Solution')`

`r SolnBegin()`  $\bar{x}_A=\frac{1}{3}(0+1+0)=\frac{1}{3}$, $\bar{x}_B=\frac{1}{3}(2+1+2)=\frac{5}{3}$

$\bar{x}=\frac{1}{2}(\frac{1}{3}+\frac{5}{3})=1$ 

With Poisson assumption the estimated variance for risk A is $\hat\sigma_A^2=\bar{x}_A=\frac{1}{3}$  

Similarly, $\hat\sigma_B^2=\bar{x}_B=\frac{5}{3}$  

$\widehat{EPV}=\frac{1}{2}(\frac{1}{3})+\frac{1}{2}(\frac{5}{3})=1$.  This is also $\bar{x}$ because of Poisson assumption.  

$\widehat{VHM}=\frac{1}{2-1}\left[(\frac{1}{3}-1)^2+(\frac{5}{3}-1)^2\right]-\frac{1}{3}=\frac{5}{9}$  

$K=\frac{1}{5/9}=\frac{9}{5}$     

$Z_A=Z_B=\frac{3}{3+(9/5)}=\frac{5}{8}$ 

$\hat{\mu}_A=\frac{5}{8}\left(\frac{1}{3}\right)+(1-\frac{5}{8})1=\frac{7}{12}$

$\hat{\mu}_B=\frac{5}{8}\left(\frac{5}{3}\right)+(1-\frac{5}{8})1=\frac{17}{12}.$  
`r SolnEnd()` 

</div>

*** 

Although we assumed that the number of claims for each risk was Poisson distributed in the prior example, we did not need this additional assumption because there was enough information to use nonparametric estimation.  In fact, the Poisson assumption might not be appropriate because for risk B the sample mean is not equal to the sample variance: $\bar{x}_B=\frac{5}{3}\neq s_B^2=\frac{1}{3}$. 

The following example is commonly used to demonstrate a situation where semiparametric estimation is needed.  There is insufficient information for nonparametric estimation but with the Poisson assumption, estimates can be calculated.


**Example  12.5.5.** A portfolio of 2,000 policyholders generated the following claims profile during a five-year period:
$$
\small{
\begin{array}{|c|c|}
\hline
\text{Number of Claims} &   \\
\text{In 5 Years}           &  \text{Number of policies}\\
\hline
 0 &  923 \\
 1 &  682 \\  
 2 &  249 \\  
 3 &  70   \\
 4 &  51   \\  
 5 &  25   \\     
\hline
\end{array}
}
$$

In your model you assume that the number of claims for each policyholder has a Poisson distribution and that a policyholder's expected number of claims is constant through time.  Use B&uuml;hlmann credibility to estimate the annual expected number of claims for policyholders with 3 claims during the five-year period.   

`r HideExample('12.5.5','Show Example Solution')`

`r SolnBegin()`  Let $\theta_i$ be the risk parameter for the $i^{th}$ risk in the portfolio with mean $\mu(\theta_i)$ and variance $\sigma^2(\theta_i)$.  With the Poisson assumption $\mu(\theta_i)=\sigma^2(\theta_i)$.  The expected value of the process variance is $EPV=\mathrm{E}(\sigma^2(\theta_i)$) where the expectation is taken across all risks in the population.  Because of the Poisson assumption for all risks it follows that $EPV=\mathrm{E}(\sigma^2(\theta_i))$ = $\mathrm{E}(\mu(\theta_i))$.  An estimate for the annual expected number of claims is $\hat{\mu}(\theta_i)$= (observed number of claims)/5.  This can also serve as the estimate for the expected value of the process variance for a risk.  Weighting the process variance estimates (or means) by the number of policies in each group gives the estimators
\begin{equation*}  
\widehat{EPV}=\bar{x}=\frac{923(0)+682(1)+249(2)+70(3)+51(4)+25(5)}{(5)(2000)}=0.1719.
\end{equation*}
Using the formula (\@ref(eq:VHM-estimate)), the $VHM$ estimator is \begin{eqnarray*}
\widehat{VHM}&=&\frac{1}{2000-1}[923(0-0.1719)^2+682(0.20-0.1719)^2+249(0.40-0.1719)^2\\
                            &   &+70(0.60-0.1719)^2+51(0.80-0.1719)^2+25(1-0.1719)^2]-\frac{0.1719}{5}\\
                            &=& 0.0111\\
               \hat{K}  &=& \widehat{EPV}/\widehat{VHM}=0.1719/0.0111=15.49\\
               \hat{Z}  &=& \frac{5}{5+15.49}=0.2440\\
               \hat{\mu}_{3 \textrm{ claims}}& = & 0.2440(3/5)+(1-0.2440)0.1719=0.2764 .\\
\end{eqnarray*}
`r SolnEnd()` 

</div>

*** 


## Limited Fluctuation Credibility {#S:Sec126}

***

In this section, you learn how to:

* Calculate full credibility standards for number of claims, average size of claims, and aggregate losses.
* Learn how the relationship between means and variances of underlying distributions affects full credibility standards.
* Determine credibility-weight $Z$ using the square-root partial credibility formula.

***

`r Gloss('Limited fluctuation credibility')`, also called "classical credibility" and "American credibility," was given this name because the method explicitly attempts to limit fluctuations in estimates for claim frequencies, severities, or losses.  For example, suppose that you want to estimate the expected number of claims $N$ for a group of risks in an insurance rating class.  How many risks are needed in the class to ensure that a specified level of accuracy is attained in the estimate?  First the question will be considered from the perspective of how many claims are needed.

### Full Credibility for Claim Frequency {#S:Sec1261}

Let $N$ be a random variable representing the number of claims for a group of risks, for example, risks within a particular rating classification.  The observed number of claims will be used to estimate $\mu_N=\mathrm{E}[N]$, the expected number of claims.  How big does $\mu_N$ need to be to get a good estimate?  One way to quantify the accuracy of the estimate would be with a statement like:  ``The observed value of $N$ should be within 5$\%$ of $\mu_N$ at least 90$\%$ of the time."   Writing this as a mathematical expression would give  $\Pr[0.95 \mu_N \leq N \leq 1.05 \mu_N] \geq 0.90$. Generalizing this statement by letting the range parameter $k$ replace 5$\%$ and probability level $p$ replace 0.90 gives the equation
\begin{equation}
\Pr[(1-k) \mu_N \leq N \leq (1+k) \mu_N] \geq p .
(\#eq:kpercent-interval)
\end{equation}
The expected number of claims required for the probability on the left-hand side of \@ref(eq:kpercent-interval) to equal $p$ is called the `r Gloss('full credibility standard')`.  

If the expected number of claims is greater than or equal to the full credibility standard then full credibility can be assigned to the data so $Z=1$.  Usually the expected value $\mu_N$ is not known so full credibility will be assigned to the data if the actual observed number of claims $n$ is greater than or equal to the full credibility standard.  The $k$ and $p$ values must be selected and the actuary may rely on experience, judgment, and other factors in making the choices.  

Subtracting $\mu_N$  from each term in \@ref(eq:kpercent-interval) and dividing by the standard deviation $\sigma_N$ of $N$ gives
\begin{equation}
\Pr\left[\frac{-k\mu_N}{\sigma_N}\leq \frac{N-\mu_N}{\sigma_N} \leq \frac{k\mu_N}{\sigma_N}\right] \geq p.
(\#eq:normalized-interval)
\end{equation}
In limited fluctuation credibility the standard normal distribution is used to approximate the distribution of $(N-\mu_N)/\sigma_N$. If $N$ is the sum of many claims from a large group of similar risks and the claims are independent, then the approximation may be reasonable.

Let $y_p$ be the value such that 
$$
\Pr[-y_p\leq \frac{N-\mu_N}{\sigma_N} \leq y_p]=\Phi(y_p)-\Phi(-y_p)=p
$$ 
where $\Phi( )$ is the `r Gloss('cumulative distribution function of the standard normal')`.  Because $\Phi(-y_p)=1-\Phi(y_p)$, the equality can be rewritten as $2\Phi(y_p)-1=p$.  Solving for $y_p$ gives $y_p=\Phi^{-1}((p+1)/2)$ where $\Phi^{-1}( )$ is the inverse of $\Phi( )$.  

Equation \@ref(eq:normalized-interval) will be satisfied if $k\mu_N/\sigma_N \geq y_p$ assuming the normal approximation.  First we will consider this inequality for the case when $N$ has a Poisson distribution:  $\Pr[N=n] = \lambda^n\textrm{e}^{-\lambda}/n!$.  Because $\lambda=\mu_N=\sigma_N^2$ for the Poisson, taking square roots yields $\mu_N^{1/2}=\sigma_N$.  So, $k\mu_N/\mu_N^{1/2} \geq y_p$ which is equivalent to $\mu_N \geq (y_p/k)^2$.  Let's define $\lambda_{kp}$ to be the value of $\mu_N$ for which equality holds.  Then the full credibility standard for the Poisson distribution is 
\begin{equation}
\lambda_{kp} = \left(\frac{y_p}{k}\right)^2 \textrm{with } y_p=\Phi^{-1}((p+1)/2).
(\#eq:full-credibility-Poisson)
\end{equation}
If the expected number of claims $\mu_N$ is greater than or equal to $\lambda_{kp}$ then equation \@ref(eq:kpercent-interval) is assumed to hold and full credibility can be assigned to the data.  As noted previously, because $\mu_N$ is usually unknown, full credibility is given if the observed number of claims $n$ satisfies $n \geq \lambda_{kp}.$



**Example 12.6.1.**  The full credibility standard is set so that the observed number of claims is to be within 5\% of the expected value with probability $p=0.95$.  If the number of claims has a Poisson distribution find the number of claims needed for full credibility.

`r HideExample('12.6.1','Show Example Solution')`

`r SolnBegin()`  Referring to a standard normal distribution table, $y_p=\Phi^{-1}((p+1)/2)=\Phi^{-1}((0.95+1)/2)$=$\Phi^{-1}(0.975)=1.960$.  Using this value and $k=.05$ then $\lambda_{kp} = (y_p/k)^{2}=(1.960/0.05)^{2}=1,536.64$.  After rounding up the full credibility standard is 1,537.
`r SolnEnd()` 

</div>

*** 

If claims are not Poisson distributed then equation \@ref(eq:normalized-interval) does not imply \@ref(eq:full-credibility-Poisson).  Setting the upper bound of $(N-\mu_N)/\sigma_N$ in \@ref(eq:normalized-interval) equal to $y_p$ gives $k\mu_N/\sigma_N=y_p$.  Squaring both sides and moving everything to the right side except for one of the $\mu_N$'s gives  $\mu_N=(y_p/k)^2(\sigma_N^2/\mu_N)$.  This is the full credibility standard for frequency and will be denoted by $n_f$,
\begin{equation}
n_f=\left(\frac{y_p}{k}\right)^2\left(\frac{\sigma_N^2}{\mu_N}\right)=\lambda_{kp}\left(\frac{\sigma_N^2}{\mu_N}\right).
(\#eq:full-credibility-frequency)
\end{equation}
This is the same equation as the Poisson full credibility standard except for the $(\sigma_N^2/\mu_N)$ multiplier. When the claims distribution is Poisson this extra term is one because the variance equals the mean.  


**Example 12.6.2.** The full credibility standard is set so that the total number of claims is to be within 5$\%$ of the observed value with probability $p=0.95$.  The number of claims has a negative binomial distribution,
$$
\Pr(N=x)={x+r-1\choose x} \left(\frac{1}{1+\beta}\right)^r \left(\frac{\beta}{1+\beta}\right)^x ,
$$
with $\beta=1$.  Calculate the full credibility standard.

`r HideExample('12.6.2','Show Example Solution')`

`r SolnBegin()`  From the prior example, $\lambda_{kp} =1,536.64$.  The mean and variance for the negative binomial are $\mathrm{E}(N)=r\beta$ and $\mathrm{Var}(N)=r\beta(1+\beta)$ so $(\sigma_N^2/\mu_N)=(r\beta(1+\beta)/(r\beta))=1+\beta$ which equals 2 when $\beta=1$.  So, $n_f=\lambda_{kp}(\sigma_N^2/\mu_N)=1,536.64(2)=3,073.28$ and rounding up gives a full credibility standard of 3,074.
`r SolnEnd()` 

</div>

*** 

We see that the negative binomial distribution with $(\sigma_N^2/\mu_N)>1$ requires more claims for full credibility than a Poisson distribution for the same $k$ and $p$ values.  The next example shows that a binomial distribution which has $(\sigma_N^2/\mu_N)<1$ will need fewer claims for full credibility.


**Example 12.6.3.** The full credibility standard is set so that the total number of claims is to be within 5$\%$ of the observed value with probability $p=0.95$.  The number of claims has a binomial distribution 
$$
\Pr(N=x)={m\choose x}q^x(1-q)^{m-x}.
$$
Calculate the full credibility standard for $q=1/4$.

`r HideExample('12.6.3','Show Example Solution')`

`r SolnBegin()`  From the first example in this section $\lambda_{kp} =1,536.64$.  The mean and variance for a binomial are $\mathrm{E}(N)=mq$ and $\mathrm{Var}(N)=mq(1-q)$ so $(\sigma_N^2/\mu_N)=(mq(1-q)/(mq))=1-q$ which equals 3/4 when $q=1/4$.  So, $n_f=\lambda_{kp}(\sigma_N^2/\mu_N)=1,536.64(3/4)=1,152.48$ and rounding up gives a full credibility standard of 1,153.
`r SolnEnd()` 

</div>

*** 

Rather than using expected number of claims to define the full credibility standard, the number of exposures can be used for the full credibility standard.  An exposure is a measure of risk.  For example, one car insured for a full year would be one car-year.  Two cars each insured for exactly one-half year would also result in one car-year.  Car-years attempt to quantify exposure to loss.  Two car-years would be expected to generate twice as many claims as one car-year if the vehicles have the same risk of loss.  To translate a full credibility standard denominated in terms of number of claims to a full credibility standard denominated in exposures one needs a reasonable estimate of the expected number of claims per exposure.  


**Example 12.6.4.** The full credibility standard should be selected so that the observed number of claims will be within 5$\%$ of the expected value with probability $p=0.95$.  The number of claims has a Poisson distribution.   If one exposure is expected to have about 0.20 claims per year, find the number of exposures needed for full credibility.  

`r HideExample('12.6.4','Show Example Solution')`

`r SolnBegin()`  With $p=0.95$ and $k=.05$, $\lambda_{kp} = (y_p/k)^{2}=(1.960/0.05)^{2}=1,536.64$ claims are required for full credibility.  The claims frequency rate is 0.20 claims per exposure.  To convert the full credibility standard to a standard denominated in exposures the calculation is:   (1,536.64 claims)/(0.20 claims/exposures) = 7,683.20 exposures.  This can be rounded up to 7,684. 
`r SolnEnd()` 

</div>

*** 

Frequency can be defined as the number of claims per exposure.  Letting $m$ denote the number of exposures. Then, if observed claim frequency $N/m$ is used to estimate $\mathrm{E}(N/m)$:  
$$
\Pr[(1-k)\mathrm{E}(N/m)\leq N/m \leq(1+k)\mathrm{E}(N/m)] \geq p.
$$
Because the number of exposures is not a random variable,  $\mathrm{E}(N/m)=\mathrm{E}(N)/m=\mu_N/m$ and the prior equation becomes
$$
\Pr\left[(1-k)\frac{\mu_N}{m}\leq \frac{N}{m} \leq(1+k)\frac{\mu_N}{m}\right] \geq p.
$$
Multiplying through by $m$ results in equation \@ref(eq:kpercent-interval) at the beginning of the section.  The full credibility standards that were developed for estimating expected number of claims also apply to frequency.


### Full Credibility for Aggregate Losses and Pure Premium

Aggregate losses are the total of all loss amounts for a risk or group of risks.  Letting $S$ represent aggregate losses
$$
S=X_1+X_2+\cdots+X_N.
$$
The random variable $N$ represents the number of losses and random variables $X_1, X_2,\ldots,X_N$ are the individual loss amounts.  In this section it is assumed that $N$ is independent of the loss amounts and that $X_1, X_2,\ldots,X_N$ are `r Gloss('iid')`.

The mean and variance of $S$ are
$$
\mu_S=\mathrm{E}(S)=\mathrm{E}(N)\mathrm{E}(X)=\mu_N\mu_X
$$
and
$$
\sigma^{2}_S=\mathrm{Var}(S)=\mathrm{E}(N)\mathrm{Var}(X)+[\mathrm{E}(X)]^{2}\mathrm{Var}(N)=\mu_N\sigma^{2}_X+\mu^{2}_X\sigma^{2}_N ,
$$
where $X$ is the amount of a single loss. See the discussion on *collective risk models* in Section \@ref(S:Sec73) for more discussion of this framework. 

Observed losses $S$ will be used to estimate expected losses $\mu_S=\mathrm{E}(S)$.  As with the frequency model in the previous section, the observed losses must be close to the expected losses as quantified in the equation
$$
\Pr[(1-k)\mu_S\leq S \leq(1+k)\mu_S] \geq p.
$$ 
After subtracting the mean and dividing by the standard deviation,
$$
\Pr\left[\frac{-k\mu_S}{\sigma_S}\leq (S-\mu_S)/\sigma_S \leq \frac{k\mu_S}{\sigma_S}\right] \geq p .
$$
As done in the previous section the distribution for $(S-\mu_S)/\sigma_S$ is assumed to be standard normal and $k\mu_S/\sigma_S=y_p=\Phi^{-1}((p+1)/2)$.  This equation can be rewritten as $\mu_S^2=(y_p/k)^2\sigma_S^2$.  Using the prior formulas for $\mu_S$ and $\sigma_{S}^2$ gives $(\mu_N\mu_X)^2=(y_p/k)^2(\mu_N\sigma^{2}_X+\mu^{2}_X\sigma^{2}_N)$.  Dividing both sides by $\mu_N\mu_X^2$ and reordering terms on the right side results in a full credibility standard $n_S$ for aggregate losses
\begin{equation}
n_S=\left(\frac{y_p}{k}\right)^2\left[\left(\frac{\sigma_N^2}{\mu_N}\right)+\left(\frac{\sigma_X}{\mu_X}\right)^2\right]=\lambda_{kp}\left[\left(\frac{\sigma_N^2}{\mu_N}\right)+\left(\frac{\sigma_X}{\mu_X}\right)^2\right].
(\#eq:full-credibility-losses)
\end{equation}


**Example 12.6.5.** The number of claims has a Poisson distribution.  Individual loss amounts are independently and identically distributed with a Pareto distribution $F(x)=1-[\theta/(x+\theta)]^{\alpha}$.  The number of claims and loss amounts are independent. If observed aggregate losses should be within 5$\%$ of the expected value with probability $p=0.95$, how many losses are required for full credibility?

`r HideExample('12.6.5','Show Example Solution')`

`r SolnBegin()`  Because the number of claims is Poisson, $(\sigma_N^2/\mu_N)=1$.  The mean of the Pareto is $\mu_X=\theta/(\alpha-1)$ and the variance is $\sigma_X^2=\theta^{2}\alpha/[(\alpha-1)^{2}(\alpha-2)]$ so $(\sigma_X/\mu_X)^2=\alpha/(\alpha-2)$.  Combining the frequency and severity terms gives $[(\sigma_N^2/\mu_N)+(\sigma_X/\mu_X)^2]=2(\alpha-1)/(\alpha-2)$.  From a standard normal distribution table $y_p=\Phi^{-1}((0.95+1)/2)=1.960$.  The full credibility standard is $n_S=(1.96/0.05)^{2}[2(\alpha-1)/(\alpha-2)]=3,073.28(\alpha-1)/(\alpha-2)$.  Suppose $\alpha=3$ then $n_S=6,146.56$ for a full credibility standard of 6,147.  Note that considerably more claims are needed for full credibility for aggregate losses than frequency alone.
`r SolnEnd()` 

</div>

*** 

When the number of claims is Poisson distributed then equation \@ref(eq:full-credibility-losses) can be simplified using $(\sigma_N^2/\mu_N)=1$.  It follows that 
$$
[(\sigma_N^2/\mu_N)+(\sigma_X/\mu_X)^2]=[1+(\sigma_X/\mu_X)^2]=[(\mu_X^2+\sigma_X^2)/\mu_X^2]=\mathrm{E}(X^2)/\mathrm{E}(X)^2
$$ 
using the relationship $\mu_X^2+\sigma_X^2=\mathrm{E}(X^2)$.  The full credibility standard is $n_S=\lambda_{kp}~\mathrm{E}(X^2)/\mathrm{E}(X)^2$.


The pure premium $PP$ is equal to aggregate losses $S$ divided by exposures $m$:  $PP=S/m$.   The full credibility standard for pure premium will require
$$
\Pr\left[(1-k)\mu_{PP}\leq PP \leq(1+k)\mu_{PP}\right] \geq p.
$$
The number of exposures $m$ is assumed fixed and not a random variable so $\mu_{PP}=\mathrm{E}(S/m)=\mathrm{E}(S)/m=\mu_S/m$. 
$$
\Pr\left[(1-k)\left(\frac{\mu_S}{m}\right)\leq \left(\frac{S}{m}\right) \leq(1+k)\left(\frac{\mu_S}{m}\right)\right] \geq p.
$$
Multiplying through by $m$ returns the bounds for losses
$$
\Pr[(1-k)\mu_S\leq S \leq(1+k)\mu_S] \geq p.
$$
This means that the full credibility standard $n_{PP}$ for the pure premium is the same as that for aggregate losses 
$$
n_{PP}=n_S=\lambda_{kp}\left[\left(\frac{\sigma_N^2}{\mu_n}\right)+\left(\frac{\sigma_X}{\mu_X}\right)^2\right].
$$


### Full Credibility for Severity

Let $X$ be a random variable representing the size of one claim.  Claim severity is $\mu_X=\mathrm{E}(X)$.  Suppose that ${X_1,X_2, \ldots, X_n}$ is a random sample of $n$ claims that will be used to estimate claim severity $\mu_X$.  The claims are assumed to be *iid*.  The average value of the sample is 
$$
\bar{X}=\frac{1}{n}\left(X_1+X_2+\cdots+X_n\right).
$$
How big does $n$ need to be to get a good estimate?  Note that $n$ is not a random variable whereas it is in the aggregate loss model.

In Section \@ref(S:Sec1261) the accuracy of an estimator for frequency was defined by requiring that the number of claims lie within a specified interval about the mean number of claims with a specified probability.  For severity this requirement is
$$
\Pr[(1-k)\mu_X\leq \bar{X} \leq(1+k)\mu_X ]\geq p ,
$$
where $k$ and $p$ need to be specified.  Following the steps in Section \@ref(S:Sec1261), the mean claim severity $\mu_X$ is subtracted from each term and the standard deviation of the claim severity estimator $\sigma_{\bar{X}}$  is divided into each term yielding
$$
\Pr\left[\frac{-k~\mu_X}{\sigma_{\bar{X}}}\leq (\bar{X}-\mu_X)/\sigma_{\bar{X}} \leq \frac{k~\mu_X}{\sigma_{\bar{X}}}\right] \geq p .
$$ 
As in prior sections, it is assumed that $(\bar{X}-\mu_X)/\sigma_{\bar{X}}$ is approximately normally distributed and the prior equation is satisfied if $k\mu_X/\sigma_{\bar{X}}\geq y_p$ with $y_p=\Phi^{-1}((p+1)/2)$.  Because $\bar{X}$ is the average of individual claims $X_1, X_2,\dots, X_n$, its standard deviation is equal to the standard deviation of an individual claim divided by $\sqrt{n}$: $\sigma_{\bar{X}}=\sigma_X/\sqrt{n}$.  So, $k\mu_X/(\sigma_X/\sqrt{n})\geq y_p$ and with a little algebra this can be rewritten as $n \geq (y_p/k)^2(\sigma_X/\mu_X)^2$.  The full credibility standard for severity is 
\begin{equation}
n_X=\left(\frac{y_p}{k}\right)^2\left(\frac{\sigma_X}{\mu_X}\right)^2=\lambda_{kp}\left(\frac{\sigma_X}{\mu_X}\right)^2.
(\#eq:full-credibility-severity)
\end{equation}
Note that the term $\sigma_X/\mu_X$ is the `r Gloss('coefficient of variation')` for an individual claim.  Even though $\lambda_{kp}$ is the full credibility standard for frequency given a Poisson distribution, there is no assumption about the distribution for the number of claims.


**Example 12.6.6.** Individual loss amounts are independently and identically distributed with a Type II Pareto distribution $F(x)=1-[\theta/(x+\theta)]^{\alpha}$.  How many claims are required for the average severity of observed claims to be within 5$\%$ of the expected severity with probability $p=0.95$?

`r HideExample('12.6.6','Show Example Solution')`

`r SolnBegin()`  The mean of the Pareto is $\mu_X=\theta/(\alpha-1)$ and the variance is $\sigma_X^2=\theta^{2}\alpha/[(\alpha-1)^{2}(\alpha-2)]$ so $(\sigma_X/\mu_X)^2=\alpha/(\alpha-2)$.  From a standard normal distribution table $y_p=\Phi^{-1}((0.95+1)/2)=1.960$.  The full credibility standard is $n_X=(1.96/0.05)^{2}[\alpha/(\alpha-2)]=1,536.64\alpha/(\alpha-2)$.  Suppose $\alpha=3$ then $n_X=4,609.92$ for a full credibility standard of 4,610.  
`r SolnEnd()` 

</div>

*** 

### Partial Credibility

In prior sections full credibility standards were calculated for estimating frequency ($n_f$), pure premium ($n_{PP}$), and severity ($n_X$) - in this section these full credibility standards will be denoted by $n_{0}$.  In each case the full credibility standard was the expected number of claims required to achieve a defined level of accuracy when using empirical data to estimate an expected value. If the observed number of claims is greater than or equal to the full credibility standard then a full credibility weight $Z=1$ is given to the data.  

In limited fluctuation credibility, credibility weights $Z$ assigned to data are
$$ 
Z=
\left\{
\begin{array}{ll}
\sqrt{n /n_{0}} &\textrm{if }   n < n_{0} \\ 
1 & \textrm{if }   n \ge n_{0} ,
\end{array}
\right.
$$

where $n_0$ is the full credibility standard.  The quantity $n$ is the number of claims for the data that is used to estimate the expected frequency, severity, or pure premium.


**Example 12.6.7.** 
The number of claims has a Poisson distribution.  Individual loss amounts are independently and identically distributed with a Type II Pareto distribution $F(x)=1-[\theta/(x+\theta)]^{\alpha}$.  Assume that $\alpha=3$. The number of claims and loss amounts are independent.  The full credibility standard is that the observed pure premium should be within 5$\%$ of the expected value with probability $p=0.95$. What  credibility $Z$ is assigned to a pure premium computed from 1,000 claims?

`r HideExample('12.6.7','Show Example Solution')`

`r SolnBegin()`  Because the number of claims is Poisson,
$$
\frac{\mathrm{E}(X^2)}{[\mathrm{E}~(X)]^2}
=\frac{\sigma_N^2}{\mu_N}+\left(\frac{\sigma_X}{\mu_X}\right)^2.  
$$
The mean of the Pareto is $\mu_X=\theta/(\alpha-1)$ and the second moment is $\mathrm{E}(X^2)=2\theta^{2}/[(\alpha-1)(\alpha-2)]$ so $\mathrm{E}(X^2)/[\mathrm{E}~(X)]^2=2(\alpha-1)/(\alpha-2)$.  From a standard normal distribution table, $y_p=\Phi^{-1}((0.95+1)/2)=1.960$.  The full credibility standard is 
$$
n_{PP}=(1.96/0.05)^{2}[2(\alpha-1)/(\alpha-2)]=3,073.28(\alpha-1)/(\alpha-2)
$$
and if $\alpha=3$ then $n_0=n_{PP}=6,146.56$ or 6,147 if rounded up.  The credibility assigned to 1,000 claims is $Z=(1,000/6,147)^{1/2}=0.40$.
`r SolnEnd()` 

</div>

*** 

Limited fluctuation credibility uses the formula $Z=\sqrt{n/n_0}$ to limit the fluctuation in the credibility-weighted estimate to match the fluctuation allowed for data with expected claims at the full credibility standard.  Variance or standard deviation is used as the measure of fluctuation.  Next we show an example to explain why the square-root formula is used.


Suppose that average claim severity is being estimated from a sample of size $n$ that is less than the full credibility standard $n_0=n_X$.  Applying credibility theory, the estimate $\hat{\mu}_X$ would be
$$
\hat{\mu}_X=Z\bar{X}+(1-Z)M_X ,
$$
with $\bar{X}=(X_1+X_2+\cdots+X_n)/n$ and $iid$ random variables $X_i$ representing the sizes of individual claims.  The complement of credibility is applied to $M_X$ which could be last year's estimated average severity adjusted for inflation, the average severity for a much larger pool of risks, or some other relevant quantity selected by the actuary.  It is assumed that the variance of $M_X$ is zero or negligible.  With this assumption
$$
\mathrm{Var}(\hat{\mu}_X)=\mathrm{Var}(Z\bar{X})=Z^2\mathrm{Var}(\bar{X})=\frac{n}{n_0}\mathrm{Var}(\bar{X}).
$$
Because $\bar{X}=(X_1+X_2+\cdots+X_n)/n$ it follows that $\mathrm{Var}(\bar{X})=\mathrm{Var}(X_i)/n$ where random variable $X_i$ is one claim.  So,
$$
\mathrm{Var}(\hat{\mu}_X)=\frac{n}{n_0}\mathrm{Var}(\bar{X})=\frac{n}{n_0}\frac{\mathrm{Var}(X_i)}{n}=\frac{\mathrm{Var}(X_i)}{n_0}.
$$
The last term is exactly the variance of a sample mean $\bar{X}$ when the sample size is equal to the full credibility standard $n_0=n_X$.


### Full Credibility Standard for Limited Fluctuation Credibility

Limited-fluctuation credibility requires a full credibility standard.  The general formula for aggregate losses or pure premium, as obtained in formula \@ref(eq:full-credibility-losses), is
$$
n_S=\left(\frac{y_p}{k}\right)^2\left[\left(\frac{\sigma_N^2}{\mu_N}\right)+\left(\frac{\sigma_X}{\mu_X}\right)^2\right] ,
$$
with $N$ representing number of claims and $X$ the size of claims.  If one assumes $\sigma_X=0$ then the full credibility standard for frequency results.  If $\sigma_N=0$ then the full credibility formula for severity follows.  Probability $p$ and $k$ value are often selected using judgment and experience.

In practice it is often assumed that the number of claims is Poisson distributed  so that $\sigma_N^2/\mu_N=1$.  In this case the formula can be simplified to 
\begin{equation*}
n_S=\left(\frac{y_p}{k}\right)^2\left[\frac{\mathrm{E}(X^2)}{(\mathrm{E}(X))^2}\right].
\end{equation*}
An empirical mean and second moment for the sizes of individual claim losses can be computed from past data, if available.


```{r child = './Quizzes/Quiz92.html', eval = QUIZ}
```


## Balancing Credibility Estimators {#S:Sec127}

The credibility weighted model $\hat{\mu}(\theta_i)=Z_i\bar{X}_i+(1-Z_i)\bar{X}$, where $\bar{X}_i$ is the loss per exposure for risk $i$ and $\bar{X}$ is loss per exposure for the population, can be used to estimate the expected loss for risk $i$.  The overall mean is $\bar{X}=\sum_{i=1}^r(m_i/m) \bar{X}_i$ where $m_i$ and $m$ are number of exposures for risk $i$ and population, respectively.  

For the credibility weighted estimators to be in balance we want 
$$  
\bar{X}=\sum_{i=1}^r(m_i/m) \bar{X}_i=\sum_{i=1}^r(m_i/m) \hat{\mu}(\theta_i).
$$
If this equation is satisfied then the estimated losses for each risk will add up to the population total, an important goal in ratemaking, but this may not happen if the complement of credibility is applied to $\bar{X}$.  

To achieve balance,  we will set $\hat{M}_X$ as the amount that is applied to the complement of credibility and thus analyze the following equation:
$$  
\sum_{i=1}^r(m_i/m) \bar{X}_i=\sum_{i=1}^r(m_i/m) \left\{Z_i\bar{X}_i+(1-Z_i) \cdot \hat{M}_X\right\} .
$$
A little algebra gives
$$   
\sum_{i=1}^r m_i \bar{X}_i=\sum_{i=1}^r m_i Z_i\bar{X}_i + \hat{M}_X\sum_{i=1}^r m_i(1-Z_i),
$$
and
$$  
\hat{M}_X=\frac{\sum_{i=1}^r m_i(1-Z_i)\bar{X}_i}{\sum_{i=1}^r m_i(1-Z_i)}.
$$
Using this value for $\hat{M}_X$  will bring the credibility weighted estimators into balance.

If credibilities $Z_i$ were computed using the B&uuml;hlmann-Straub model, then $Z_i=m_i/(m_i+K)$.  The prior formula can be simplified using the following relationship
$$  
m_i(1-Z_i)=m_i\left(1-\frac{m_i}{m_i+K}\right)=m_i\left(\frac{(m_i+K)-m_i}{m_i+K}\right)=KZ_i .
$$
Therefore, an amount when applied to the complement of credibility that will bring the credibility-weighed estimators into balance with the overall mean loss per exposure is
$$  
\hat{M}_X=\frac{\sum_{i=1}^r  Z_i \bar{X}_i}{\sum_{i=1}^r  Z_i}. 
$$
 

**Example 12.7.1.** An example from the nonparametric B&uuml;hlmann-Straub section had the following data for two risks.  Find an amount for the complement of credibility $\hat{M}_X$ that will produce credibility-weighted estimates that are in balance.
$$
\small{
\begin{array}{|c|c|c|c|c|c|}
\hline
\text{Policyholder} &  & \text{Year 1} & \text{Year 2} & \text{Year 3} & \text{Year 4} \\
\hline
\text{A} & \text{Number of claims} & 0 & 2 & 2 & 3 \\
\hline
\text{A} & \text{Insured vehicles} &  1 & 2 & 2 & 2\\  
\hline
 & & & & & \\
\hline
\text{B} & \text{Number of claims} & 0 & 0 & 1 & 2\\    
\hline 
\text{B} & \text{Insured vehicles} &  0 & 2 & 3 & 4\\      
\hline
\end{array}
}
$$

`r HideExample('12.7.1','Show Example Solution')`

`r SolnBegin()`  The credibilities from the prior example are $Z_A=\frac{7}{7+2.0871}=0.7703$ and $Z_B=\frac{9}{9+2.0871}=0.8118$.  The sample means are $\bar{x}_A=1$ and $\bar{x}_B=1/3$.  The balanced complement of credibility is
$$  
\hat{M}_X=\frac{0.7703(1)+0.8118(1/3)}{0.7703+0.8118}=0.6579.
$$
The updated credibility estimates are $\hat{M}_{X_A}=0.7703(1)+(1-0.7703)(.6579)=0.9214$ versus the previous 0.9139 and $\hat{M}_{X_B}=0.8118(1/3)+(1-0.8118)(.6579)=0.3944$ versus the previous 0.3882.  Checking the balance on the new estimators:  (7/16)(0.9214)+(9/16)(0.3944)=0.6250.  This exactly matches $\bar{X}=10/16=0.6250$.
`r SolnEnd()` 


</div>

*** 


```{r child = './Quizzes/Quiz96.html', eval = QUIZ}
```


## Further Resources and Contributors {#S:Sec128}


#### Contributor {-}

- **Gary Dean**, Ball State University is the author of the initial version of this chapter. Email: <cgdean@bsu.edu> for chapter comments and suggested improvements.
- Chapter reviewers include: Liang (Jason) Hong, Ambrose Lo, Ranee Thiagarajah, Hongjuan Zhou.



